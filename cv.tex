%-----------------------------------------------------------------------------------------------------------------------------------------------%
%	The MIT License (MIT)
%
%	Copyright (c) 2021 Jitin Nair
%
%	Permission is hereby granted, free of charge, to any person obtaining a copy
%	of this software and associated documentation files (the "Software"), to deal
%	in the Software without restriction, including without limitation the rights
%	to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
%	copies of the Software, and to permit persons to whom the Software is
%	furnished to do so, subject to the following conditions:
%	
%	THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
%	IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
%	FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
%	AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
%	LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
%	OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
%	THE SOFTWARE.
%	
%
%-----------------------------------------------------------------------------------------------------------------------------------------------%

%----------------------------------------------------------------------------------------
%	DOCUMENT DEFINITION
%----------------------------------------------------------------------------------------

% article class because we want to fully customize the page and not use a cv template
\documentclass[a4paper,12pt]{article}

%----------------------------------------------------------------------------------------
%	FONT
%----------------------------------------------------------------------------------------

% % fontspec allows you to use TTF/OTF fonts directly
% \usepackage{fontspec}
% \defaultfontfeatures{Ligatures=TeX}

% % modified for ShareLaTeX use
% \setmainfont[
% SmallCapsFont = Fontin-SmallCaps.otf,
% BoldFont = Fontin-Bold.otf,
% ItalicFont = Fontin-Italic.otf
% ]
% {Fontin.otf}

%----------------------------------------------------------------------------------------
%	PACKAGES
%----------------------------------------------------------------------------------------
\usepackage{url}
\usepackage{parskip} 	

%other packages for formatting
\RequirePackage{color}
\RequirePackage{graphicx}
\usepackage[usenames,dvipsnames]{xcolor}
\usepackage[scale=0.9]{geometry}

%tabularx environment
\usepackage{tabularx}

%for lists within experience section
\usepackage{enumitem}

% centered version of 'X' col. type
\newcolumntype{C}{>{\centering\arraybackslash}X} 

%to prevent spillover of tabular into next pages
\usepackage{supertabular}
\usepackage{tabularx}
\newlength{\fullcollw}
\setlength{\fullcollw}{0.47\textwidth}

%custom \section
\usepackage{titlesec}				
\usepackage{multicol}
\usepackage{multirow}

%CV Sections inspired by: 
%http://stefano.italians.nl/archives/26
\titleformat{\section}{\Large\scshape\raggedright}{}{0em}{}[\titlerule]
\titlespacing{\section}{0pt}{10pt}{10pt}

%for publications
\usepackage[style=authoryear,sorting=ynt, maxbibnames=2]{biblatex}

%Setup hyperref package, and colours for links
\usepackage[unicode, draft=false]{hyperref}
\definecolor{linkcolour}{rgb}{0,0.2,0.6}
\hypersetup{colorlinks,breaklinks,urlcolor=linkcolour,linkcolor=linkcolour}
\addbibresource{citations.bib}
\setlength\bibitemsep{1em}

%for social icons
\usepackage{fontawesome5}

%debug page outer frames
%\usepackage{showframe}

%----------------------------------------------------------------------------------------
%	BEGIN DOCUMENT
%----------------------------------------------------------------------------------------
\begin{document}

% non-numbered pages
\pagestyle{empty} 

%----------------------------------------------------------------------------------------
%	TITLE
%----------------------------------------------------------------------------------------

% \begin{tabularx}{\linewidth}{ @{}X X@{} }
% \huge{Your Name}\vspace{2pt} & \hfill \emoji{incoming-envelope} email@email.com \\
% \raisebox{-0.05\height}\faGithub\ username \ | \
% \raisebox{-0.00\height}\faLinkedin\ username \ | \ \raisebox{-0.05\height}\faGlobe \ mysite.com  & \hfill \emoji{calling} number
% \end{tabularx}

\begin{tabularx}{\linewidth}{@{} C @{}}
\Huge{Ahmed Tidiane BALDE} \\[7.5pt]
\href{https://github.com/ATidiane}{\raisebox{-0.05\height}\faGithub\ atidiane} \ $|$ \ 
\href{https://linkedin.com/in/ahmed-balde}{\raisebox{-0.05\height}\faLinkedin\ ahmed-balde} \ $|$ \ 
\href{https://mysite.com}{\raisebox{-0.05\height}\faGlobe \ mysite.com} \ $|$ \ 
\href{mailto:ahmedt.balde@gmail.com}{\raisebox{-0.05\height}\faEnvelope \ ahmedt.balde@gmail.com} \ $|$ \ 
\href{tel:+33 6 69 78 36 06}{\raisebox{-0.05\height}\faMobile \ +33 6.69.78.36.06} \\
\end{tabularx}

%----------------------------------------------------------------------------------------
% EXPERIENCE SECTIONS
%----------------------------------------------------------------------------------------

%Interests/ Keywords/ Summary
\section{Summary}
This CV is automatically generated and deployed using the \href{https://github.com/jitinnair1/autoCV}{autoCV} template along with GitHub Actions such that a new version of the CV is compiled, published and ready for use when the cv.tex file is updated. For details, \href{https://github.com/jitinnair1/autoCV}{click here}.

%Experience
\section{Work Experience}

\begin{tabularx}{\linewidth}{ @{}l r@{} }
\textbf{Machine Learning Engineer} & \hfill Dec 2022 - Présent \\
\textit{Pivot \& Co} & \hfill Paris \\[3.75pt]
\textbf{R\&D Proof-of-concepts} & \hfill Internal \\
\multicolumn{2}{@{}X@{}}{
\begin{minipage}[t]{\linewidth}
    \begin{itemize}[nosep,after=\strut, leftmargin=1em, itemsep=3pt]
        \item[--] Test d’un proof-of-concept avec PrivateGPT, consistant à créer des vectors stores de nouveaux documents avec ChromaDB en local, puis d’utiliser un Large Language Model (LLM) en l’occurrence GPT4ALL-J pour comprendre les questions et y répondre en s’aidant du contexte local;
        \item[--] FineTuning d’un LLM open source basé sur Llama en l’occurrence RedPajama en utilisant du Parameter Efficient Fine Tuning (PEFT) et Low Rank Adapdation (LoRA) sur les légistations ESG;
    \end{itemize}
    \end{minipage}
}
\end{tabularx}

\begin{tabularx}{\linewidth}{ @{}l r@{} }        
\textbf{Mise en place d’une pipeline de données et développement de logiciels} & \hfill Eurazeo \\
\textbf{pour la conformité aux régulations ESG} & \hfill  \\[3.75pt]
\multicolumn{2}{@{}X@{}}{
\begin{minipage}[t]{\linewidth}
    \begin{itemize}[nosep,after=\strut, leftmargin=1em, itemsep=3pt]
        \item[--] Mise en place et alimentation d’un modèle de données sur Snowflake;
        \item[--] Développement d’un package pour extraire les données du data warehouse, calculer les métriques ESG des différentes d’entreprises et fonds d’investissements que composent notre client et pousser les résultats sur Snowflake;
        \item[--] Création d’un chatbot-intent pour répondre à des questions sur les législations ESG :
        \begin{itemize}[nosep,after=\strut, leftmargin=1em, itemsep=3pt]
            \item[$\ast$] Prétaitement des données textuelles avec NLTK, tokenisation, lemmatisation, suppression des ponctuations;
            \item[$\ast$] Tests de différentes méthodes de \textit{vectorisation de mots}, bag of words, puis Word2Vec (Skip-gram, CBOW);
            \item[$\ast$] Création du Dataset du DataLoader avec Pytorch et mise en place d’un modèle de classification d’intentions constitué de quelques couches linéaires séparés par des fonctions d’activations (ReLU);
            \item[$\ast$] Entraînement du modèle et développement de l’interactivité du Chatbot.
        \end{itemize}
        \item[--] Versionning des différentes étapes du projet sur Git.
    \end{itemize}
    \end{minipage}
}
\end{tabularx}

\begin{tabularx}{\linewidth}{ @{}l r@{} }
\textbf{Développement d’un modèle de prédiction d’attrition} & \hfill GS1 France \\[3.75pt]
\multicolumn{2}{@{}X@{}}{
\begin{minipage}[t]{\linewidth}
    \begin{itemize}[nosep,after=\strut, leftmargin=1em, itemsep=3pt]
        \item[--] Analyse, prétraitement et visualisation des données clients pour comprendre les types de clients qui résilient leurs abonnements;
        \item[--] Traitement des valeurs aberrantes avec une approche métier et l’approche interquartile;
        \item[--] Traitement des valeurs manquantes et calculs de tests statistiques et de variance inflation factor (VIF) pour éviter les problèmes de mutlicolinéarité;
        \item[--] Prédiction de la probabilité d’attrition pour chacun des adhérents avec des modèles d’arbres de décision tels que Xtreme Gradient Boosting \textit{XGBoost};
        \item[--] Interprétation des modèles avec l’approche TreeExplainer de Shap pour comprendre l’importance qu’a chaque variable (feature) sur les résultats;
        \item[--] Ajout de loggings pour monitorer l’exécution des scripts;
        \item[--] Structuration du projet sur GitLab pour faciliter le déploiement.
    \end{itemize}
    \end{minipage}
}
\end{tabularx}

\begin{tabularx}{\linewidth}{ @{}l r@{} }
\textbf{Prédiction de ventes en volumes sur trois (3) années pour plusieurs marques} & \hfill BEL GROUP \\
\textbf{de différents pays au sein du groupe} & \hfill  \\[3.75pt]
\multicolumn{2}{@{}X@{}}{
\begin{minipage}[t]{\linewidth}
    \begin{itemize}[nosep,after=\strut, leftmargin=1em, itemsep=3pt]
        \item[--] Analyse des données de ventes en volume pour comprendre la saisonnalité;
        \item[--] Prédire les ventes en volume sur trois (3) années pour chacune des marques en utilisant des modèles logistiques et linéaires de la librairie Prophet, avec et sans regressors;
        \item[--] Mise en place de scénarios en variant les inputs (regressors) pour ainsi prédire l’impact qu’a chaque feature dans la projection des ventes en volume;
        \item[--] Préparation de workshops au sein de sept (7) pays pour présenter les résultats et expliquer nos modèles et leurs limites.
    \end{itemize}
    \end{minipage}
}
\end{tabularx}

\begin{tabularx}{\linewidth}{ @{}l r@{} }
\textbf{Mentor Data Scientist} & \hfill Fev 2023 - Présent \\
\textit{OpenClassrooms} & \hfill Paris \\[3.75pt]
\textbf{Accompagnement d'étudiants dans la réalisation des projets} & \hfill \href{https://openclassrooms.com/fr/paths/793-data-scientist}{voir Parcours} \\
\multicolumn{2}{@{}X@{}}{
\begin{minipage}[t]{\linewidth}
    \begin{itemize}[nosep,after=\strut, leftmargin=1em, itemsep=3pt]
        \item[--] Présenter les projets et expliquer les attentes et compétences à valider;
        \item[--] Guider et répondre aux questions techniques et théoriques des étudiants sur les notions de Data Science;
        \item[--] Définir les objectifs à atteindre pour chaque étudiant pour la session suivante et s’assurer à respecter le délai défini en amont pour la validation de chacun des projets;
        \item[--] Rédiger un rapport hebdomadaire sur leur progression;
        \item[--] Valider les livrables des étudiants avant de les présenter à la soutenance.
    \end{itemize}
    \end{minipage}
}
\end{tabularx}

\begin{tabularx}{\linewidth}{ @{}l r@{} }
\textbf{Machine Learning and Software Engineer} & \hfill Mars 2021 - Nov 2021 \\
\textit{Institut National de Recherche en Informatique et en Automatique (INRIA)} & \hfill Paris \\[3.75pt]
\textbf{Développement d'un système de protection piétons} & \hfill \href{https://ipya.eu/}{voir IPYA} \\
\multicolumn{2}{@{}X@{}}{
\begin{minipage}[t]{\linewidth}
    \begin{itemize}[nosep,after=\strut, leftmargin=1em, itemsep=3pt]
        \item[--] Création du Dataset et du DataLoader avec PyTorch sur la base de données JAAD (Joint Attention for Autonomous Driving) spécifiquement amélioré avec plus de labels sur ce projet;
        \item[--] Etat de l’art sur les modèles de détection, de tracking, de segmentation et de prédiction d’action;
        \item[--] Finetuning d’algorithmes de détections (yolov5) sur les données pour la détection de piétons;
        \item[--] Exploration d’algorithmes de tracking SORT (Simple Online and Real Time Tracking) et DeepSort;
        \item[--] Exploration d’algorithmes de segmentation tels que BiseNet et DDRN ainsi que d’autres qui sont plus à l’état de l’art comme HyperSeg, dans l’objectif de différencier un piéton se trouvant sur la chaussée et un autre se trouvant sur le trottoir;
        \item[--] Recherche et Développement sur les modèles de prédiction afin de prédire le TTE (Time-To-Event), à titre d’exemple, le piéton va-t-il traverser dans 1, 3, ou 5 secondes;
        \item[--] Développement de modèles à base de LSTMs pour prédire l’action future en prenant en entrée une fenêtre d’une demi-seconde d’actions passées (30 frames);
        \item[--] Prédiction de l’action de la frame suivante, puis de celle à 1 seconde (30 frames), puis 3 secondes (90 frames) et ainsi de suite;
        \item[--] Projection de la région d’intérêt (ROI) du piéton (2D) vers une dimension (1D) puis concaténation avec des données contextuelles et de l’action correspondante aux différents ROIs, et prédiction de l’action future;
        \item[--] R\&D de modèles à base de couches de transformers à la place de LSTMs;
        \item[--] Déploiement du meilleur modèle sur Nvidia Jetson Nano, conversion de modèles en ONNX puis adaptation en TensorRT afin de faire des tests en temps réel en voiture en Île-de-France.
    \end{itemize}
    \end{minipage}
}
\end{tabularx}

\begin{tabularx}{\linewidth}{ @{}l r@{} }
\textbf{R\&D Deep Learning Engineer Intern} & \hfill Mars 2020 - Août 2020 \\
\textit{Groupe PSA} & \hfill Velizy Villacoublay \\[3.75pt]
\multicolumn{2}{@{}X@{}}{
\begin{minipage}[t]{\linewidth}
\textbf{Classification d’intentions piétons par intelligence artificielle pour le véhicule autonome}
    \begin{itemize}[nosep,after=\strut, leftmargin=1em, itemsep=3pt]
        \item[--] État de l’art, prise en main des données JAAD (Joint Attention for Autonomous Driving) et PIE (Pedestrian Intent Estimation);
        \item[--] Récupérer les keypoints des différents piétons avec un algorithme de pose estimation notamment AlphaPose;
        \item[--] Classification de piétons avec des modèles de réseaux de neurones
récurrents tels que Long Short Term Memory (LSTMs);
        \item[--] Exploration des transformers dans la continuité du projet;
        \item[--] Présentation de papiers de recherches (RNNs, GRU) durant les workshops;
        \item[--] Dépôt de brevet sur les travaux à l’institut national de propriété industrielle (INPI) sous le numéro \textsc{FR3119480A1} : A method and apparatus for controlling a vehicle based on a prediction of a pedestrian’s intention to cross a roadway on which said vehicle is traveling.
    \end{itemize}
    \end{minipage}
}
\end{tabularx}

\begin{tabularx}{\linewidth}{ @{}l r@{} }
\textbf{Data Science Intern} & \hfill Juillet 2019 - Août 2019 \\
\textit{Data Factory} & \hfill Bruxelles \\[3.75pt] 
\multicolumn{2}{@{}X@{}}{
\begin{minipage}[t]{\linewidth}
\textbf{Prévision des retards des trains dans les transports publics bruxellois}
    \begin{itemize}[nosep,after=\strut, leftmargin=1em, itemsep=3pt]
        \item[--] Créer un script pour collecter des données quotidiennement avec AWS EC2 instance;
        \item[--] Analyser la situation actuelle et les tendances existantes telles que les trains ou les gares qui cumulent le plus de retards dans les différentes régions;
        \item[--] Créer des visualisations claires et interactives (plot.ly et matplotlib bibliothèques) sur les cartes pour expliquer les résultats de mon analyse des données;
        \item[--] Développer des modèles d’ensembles et des baselines tels qu’une simple régression linéaire pour prédire les retards avec les données prétraitées.
    \end{itemize}
    \end{minipage}
}
\end{tabularx}

\begin{tabularx}{\linewidth}{ @{}l r@{} }
\textbf{Prévision des salaires des joueurs de football de la Jupiler Pro League}  & \hfill \href{https://atidiane.github.io/fifa-storyline/}{voir storyline} \\[3.75pt]
\multicolumn{2}{@{}X@{}}{
\begin{minipage}[t]{\linewidth}
    \begin{itemize}[nosep,after=\strut, leftmargin=1em, itemsep=3pt]
        \item[--] Faire du scraping (beautifulsoup4) pour recueillir des données sur les joueurs de la Jupiler Pro League;
        \item[--] Fusionner les données collectées avec d’autres sources pour obtenir plus d’informations sur les joueurs;
        \item[--] Nettoyer, prétraiter et prédire les salaires des joueurs;
        \item[--] Faire une storyline sur les salaires dans le football avec des visualisations interactives puis y intégrer une simple régréssion linéaire pour prédire les salaires en fonction des caractéristiques du joueur sélectionné ainsi qu’un KNN (K-Nearest Neighbors) pour trouver les cinq joueurs Jupiler Pro League les plus proches de ces mêmes caractéristiques.
    \end{itemize}
    \end{minipage}
}
\end{tabularx}

\begin{tabularx}{\linewidth}{ @{}l r@{} }
\textbf{Assistant de recherche en Machine Learning} & \hfill Nov 2018 - Fev 2019 \\
\textit{Laboratoire Informatique de Paris 6 (LIP6/CNRS)} & \hfill Paris \\[3.75pt]
\multicolumn{2}{@{}X@{}}{
\begin{minipage}[t]{\linewidth}
\textbf{Prédiction de l’affluence dans les stations de RER de l’île de France}
    \begin{itemize}[nosep,after=\strut, leftmargin=1em, itemsep=3pt]
        \item[--] Prise en main de la base de données MySQL des logs de validation des titres de transports;
        \item[--] Recherche de données publiques à caractère socio-économiques sur la population de l’Île-de-France;
        \item[--] Création, pré-traitement des jeux de données et application de la Backward Elimination pour la sélection de features;
        \item[--] Test de différents algorithmes de régression avancée tels que eXtreme Gradient Boosting (XGBoost), Random Forest;
        \item[--] Amélioration des résultats par une méthode d’Ensemble Learning, Stacking models.
    \end{itemize}
    \end{minipage}
}
\end{tabularx}


%\begin{tabularx}{\linewidth}{ @{}l r@{} }
%\textbf{Designation} & \hfill Jan 2021 - present \\[3.75pt]
%\multicolumn{2}{@{}X@{}}{long long line of blah blah that will wrap when the table fills the column width long long line of blah blah that will wrap when the table fills the column width long long line of blah blah that will wrap when the table fills the column width long long line of blah blah that will wrap when the table fills the column width}  \\
%\end{tabularx}

%Projects
\section{Projets}

\begin{tabularx}{\linewidth}{ @{}l r@{} }
\textbf{Convolutional Neural Networks} & \hfill \href{https://github.com/ATidiane/RDFIA/tree/master/TMEs/tp6-7}{voir sur GitHub} \\[3.75pt]
\multicolumn{2}{@{}X@{}}{Implémentation d’un réseau de neurones convolutifs dont l’architecture est proche d’AlexNet, pour la classification d’images sur la base CIFAR-10}.
\end{tabularx}

\begin{tabularx}{\linewidth}{ @{}l r@{} }
\textbf{Image Description with SIFT, bag of words  and SVM Classification} & \hfill \href{https://github.com/ATidiane/RDFIA/tree/master/TMEs/tp1-2-3}{voir sur GitHub} \\
[3.75pt]
\multicolumn{2}{@{}X@{}}{Dans le cadre d’un cours sur la reconnaissance des formes et l’interprétration d’images, nous avons été introduit au SIFT (Scale Invariant Feature Transform), qui est un descripteur d’image robuste à la rotation, la variation d’intensité ainsi qu’au zoom. Après avoir calculé les descripteurs de nos images distinctes, nous avons appliqué un K-Means avec un k défini à 1001 pour trouver les centres des clusters qui représentent au mieux les images. Le dernier cluster étant un vecteur de zéros pour les descripteurs vides. Puis, nous assignâmes à chacun des clusters, sa région la plus proche. Enfin, pour la tâche de classification, nous avons généré des caractéristiques pour chacune des images en fonction de notre dictionnaire visuel des régions.}
\end{tabularx}

\begin{tabularx}{\linewidth}{ @{}l r@{} }
\textbf{Inpainting} & \hfill \href{https://github.com/ATidiane/ARF/tree/master/InpaintingProject}{voir sur GitHub} \\[3.75pt]
\multicolumn{2}{@{}X@{}}{Dans un premier temps nous avons comparé la performance des algorithmes tels que la régression linéaire et la régression ridge sur les données USPS(United states Postal Service) pour la reconnaissance des chiffres et dans un second temps nous avons implémenté un ensemble de fonctions utilisant l’algorithme du Lasso pour prédire les pixels manquants d’une image. En un mot débruiter une image ou compléter une partie d’image manquante.} \\
\end{tabularx}

% Example
%\begin{tabularx}{\linewidth}{ @{}l r@{} }
%\textbf{Some Project} & \hfill \href{https://some-link.com}{Link to Demo} \\[3.75pt]
%\multicolumn{2}{@{}X@{}}{long long line of blah blah that will wrap when the table fills the column width long long line of blah blah that will wrap when the table fills the column width long long line of blah blah that will wrap when the table fills the column width long long line of blah blah that will wrap when the table fills the column width}  \\
%\end{tabularx}

%----------------------------------------------------------------------------------------
%	EDUCATION
%----------------------------------------------------------------------------------------
\section{Formation}
\begin{tabularx}{\linewidth}{@{}l X@{}}	
2017 - 2020 & Master DAC (Données, Apprentissage et Connaissance) à \textbf{Sorbonne Université Sciences} \hfill \normalsize (Mention Bien) \\

2015 - 2017 & Licence Mono-Informatique à l'\textbf{Université de Pierre et Marie Curie (UPMC)} \hfill (Mention Assez Bien) \\ 

2014-2015 & Licence 1 Mathématiques-Informatique à l'Université Claude Bernard de Lyon1 (UCBL)\\

2014 & Baccalauréat Scientifique au Lycée Sainte Marie en Guinée \\
\end{tabularx}

%----------------------------------------------------------------------------------------
%	PUBLICATIONS
%----------------------------------------------------------------------------------------
\section{Publications}
\begin{refsection}[citations.bib]
\nocite{*}
\printbibliography[heading=none]
\end{refsection}

%----------------------------------------------------------------------------------------
%	SKILLS
%----------------------------------------------------------------------------------------
\section{Skills}
\begin{tabularx}{\linewidth}{@{}l X@{}}
Some Skills &  \normalsize{This, That, Some of this and that etc.}\\
Some More Skills  &  \normalsize{Also some more of this, Some more that, And some of this and that etc.}\\  
\end{tabularx}

\vfill
\center{\footnotesize Last updated: \today}

\end{document}
